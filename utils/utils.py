import pandas as pd
from sklearn.preprocessing import RobustScaler
from sklearn.neighbors import NearestNeighbors
import os
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np


def load_css(css_file):
    """
    Charge et applique un fichier CSS externe pour styliser l'application Streamlit.
    Args:
        css_file (str): Chemin du fichier CSS.
    """
    if os.path.exists(css_file):
        with open(css_file, 'r', encoding='utf-8') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    else:
        st.error(f"Fichier CSS non trouv√©: {css_file}")

def load_files(files='films'):
    """
    Charge les fichiers de donn√©es depuis des fichiers CSV.
    Cette fonction permet de charger un ou plusieurs fichiers CSV contenant des donn√©es n√©cessaires √† l'application.
    Elle g√®re les erreurs si le fichier est introuvable ou si le chemin est incorrect.
    Args:
        files (str ou list):
            - Si c'est une cha√Æne de caract√®res (str), elle correspond au nom de base du fichier CSV √† charger.
            - Si c'est une liste (list), elle contient plusieurs noms de base de fichiers CSV √† charger.
    Returns:
        pd.DataFrame ou list:
            - Si un seul fichier est charg√©, retourne un DataFrame Pandas.
            - Si plusieurs fichiers sont charg√©s, retourne une liste de DataFrames Pandas.
    Raises:
        FileNotFoundError: Si un ou plusieurs fichiers sont introuvables.
        ValueError: Si l'argument `files` n'est ni une cha√Æne ni une liste.
    """
    if isinstance(files, str):
        try:
            path = f'csv/{files}_def.csv'
            return pd.read_csv(path)
        except FileNotFoundError:
            raise FileNotFoundError(f"Le fichier '{path}' est introuvable. V√©rifiez le chemin.")
        except Exception as e:
            raise RuntimeError(f"Une erreur inattendue est survenue lors du chargement du fichier '{path}': {e}")
    elif isinstance(files, list):
        dataframes = []
        for file in files:
            try:
                path = f'csv/{file}_def.csv'
                df = pd.read_csv(path)
                dataframes.append(df)
            except FileNotFoundError:
                raise FileNotFoundError(f"Le fichier '{path}' est introuvable. V√©rifiez le chemin.")
            except Exception as e:
                raise RuntimeError(f"Une erreur inattendue est survenue lors du chargement du fichier '{path}': {e}")
        return dataframes
    else:
        raise ValueError("L'argument 'files' doit √™tre une cha√Æne (str) ou une liste de cha√Ænes (list).")

def prepare_features(df):
    """
    Pr√©pare les caract√©ristiques n√©cessaires au syst√®me de recommandation de films.
    √âtapes du traitement :
    - Normalisation des colonnes num√©riques √† l'aide de RobustScaler.
    - Encodage des genres de films sous forme de colonnes binaires.
    Args:
        df (pd.DataFrame): Le DataFrame des films d'origine.
    Returns:
        pd.DataFrame: DataFrame contenant les caract√©ristiques finales pr√™tes pour l'algorithme de recommandation.
    """
    X = df.copy()
    X['year'] = pd.to_datetime(X['release_date']).dt.year  # Extraction de l'ann√©e √† partir de la date de sortie
    numeric_features = ['averageRating', 'popularity', 'year']
    # Normalisation des caract√©ristiques num√©riques
    scaler = RobustScaler()
    X[numeric_features] = scaler.fit_transform(X[numeric_features])
    # Encodage des genres en colonnes binaires
    genres_split = X['genres'].str.split(',').apply(lambda x: [genre.strip() for genre in x])
    genres_dummies = pd.get_dummies(genres_split.explode()).groupby(level=0).sum()
    # Concat√©nation des colonnes num√©riques et des genres encod√©s
    final_features = pd.concat([
        X[numeric_features],
        genres_dummies
    ], axis=1)
    return final_features

def get_recommendations(title, df, features_df, n_recommendations=5, genre_weight=10):
    try:
        movie_index = df[df['title'] == title].index[0]
        genre_columns = [col for col in features_df.columns if col not in ['averageRating', 'popularity', 'year']]
        
        weighted_features = features_df.copy()
        for genre in genre_columns:
            if features_df.iloc[movie_index][genre] == 1:
                weighted_features[genre] = weighted_features[genre] * genre_weight
        
        model = NearestNeighbors(n_neighbors=n_recommendations + 1, metric='euclidean')
        model.fit(weighted_features)
        
        distances, indices = model.kneighbors(weighted_features.iloc[movie_index:movie_index+1])
        
        return df.iloc[indices[0][1:]]
    except Exception as e:
        st.error(f"Erreur dans get_recommendations: {e}")
        return pd.DataFrame()


def format_movie_info(movie):
    try:
        return f"""### üé¨ {movie['title']}
**‚≠ê Note:** {movie['averageRating']}/10
**üìÖ Ann√©e:** {movie['release_date'][:4] if pd.notna(movie['release_date']) else 'Non disponible'}
**üé≠ Genre:** {movie['genres'] if pd.notna(movie['genres']) else 'Non sp√©cifi√©'}

#### üìù Synopsis
{movie.get('overview', 'Synopsis non disponible')}
"""
    except Exception as e:
        st.error(f"Erreur dans format_movie_info: {e}")
        return "Information non disponible"

@st.cache_data(ttl=600)  # Mise en cache des r√©sultats de recherche pendant 10 minutes
def search_movies(query, films_df, intervenants_df, lien_df, n_recommendations=5):
    """
    Fonction optimis√©e de recherche de films par mot-cl√© ou nom d'acteur.
    
    Args:
        query (str): Requ√™te de recherche
        films_df (pd.DataFrame): DataFrame avec les films
        intervenants_df (pd.DataFrame): DataFrame avec les acteurs et r√©alisateurs
        lien_df (pd.DataFrame): DataFrame reliant les films et les personnes
        n_recommendations (int): Nombre de r√©sultats √† retourner
    
    Returns:
        pd.DataFrame: Films trouv√©s
    """
    try:
        # V√©rification pr√©liminaire d'une requ√™te vide
        if not query or query.strip() == "":
            return films_df.head(n_recommendations)

        query = query.lower()  # Conversion de la requ√™te en minuscules une seule fois
        
        # Recherche rapide par acteurs - utilise l'indexation pour la vitesse
        actor_matches = intervenants_df[intervenants_df['primaryName'].str.lower().str.contains(query, na=False)]
        
        if not actor_matches.empty:
            # Prenons seulement le premier acteur trouv√©
            actor_nconst = actor_matches.iloc[0]['nconst']
            
            # R√©cup√©ration des films avec cet acteur
            actor_movies = lien_df[lien_df['nconst'] == actor_nconst]
            matched_films = films_df[films_df['tconst'].isin(actor_movies['tconst'])]
            
            if not matched_films.empty:
                return matched_films.head(n_recommendations)
        
        # Cr√©ation optimis√©e du masque pour la recherche
        # Recherche d'abord uniquement dans les champs les plus importants pour acc√©l√©rer
        essential_mask = (
            films_df['title'].str.lower().str.contains(query, na=False) |
            films_df['genres'].str.lower().str.contains(query, na=False)
        )
        
        essential_matches = films_df[essential_mask]
        
        if not essential_matches.empty:
            return essential_matches.head(n_recommendations)
        
        # Recherche √©tendue seulement si n√©cessaire
        extended_mask = (
            films_df['overview'].str.lower().str.contains(query, na=False) |
            films_df['keywords'].str.lower().str.contains(query, na=False) |
            films_df['tagline'].str.lower().str.contains(query, na=False) |
            films_df['origin_country'].str.lower().str.contains(query, na=False)
        )
        
        extended_matches = films_df[extended_mask]
        
        if not extended_matches.empty:
            return extended_matches.head(n_recommendations)
            
        # TF-IDF utilis√© uniquement en dernier recours, lorsque la recherche directe n'a donn√© aucun r√©sultat
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity
        
        # Cr√©ation du texte de recherche uniquement pour un sous-ensemble de champs importants
        # et avec une multiplication moindre pour overview
        films_df['search_text'] = (
            films_df['title'].fillna('') + ' ' +
            films_df['overview'].fillna('') + ' ' +
            films_df['keywords'].fillna('') + ' ' +
            films_df['genres'].fillna('')
        )
        
        # Nombre r√©duit de max_features pour acc√©l√©rer
        tfidf = TfidfVectorizer(
            stop_words='english',
            max_features=2000,  # R√©duit de 5000
            ngram_range=(1, 1)  # Utilisation uniquement des unigrammes pour la vitesse
        )
        
        tfidf_matrix = tfidf.fit_transform(films_df['search_text'])
        query_vec = tfidf.transform([query])
        similarity = cosine_similarity(query_vec, tfidf_matrix)
        top_indices = similarity[0].argsort()[-n_recommendations:][::-1]
        
        return films_df.iloc[top_indices]
        
    except Exception as e:
        st.error(f"Erreur dans search_movies: {str(e)}")
        return films_df.head(n_recommendations)  # Retour des films populaires en cas d'erreur

# Fonctions d'authentification simplifi√©es (sans Supabase)
def check_authentication():
    """V√©rifie si l'utilisateur est connect√©."""
    # Toujours retourner False car l'authentification est d√©sactiv√©e
    return False

def handle_signup(email, password):
    """Gestion de l'inscription."""
    st.warning("L'authentification est d√©sactiv√©e dans cette version de l'application.")
    return

def handle_login(email, password):
    """Gestion de la connexion."""
    st.warning("L'authentification est d√©sactiv√©e dans cette version de l'application.")
    return

def handle_logout():
    """D√©connexion de l'utilisateur."""
    st.warning("L'authentification est d√©sactiv√©e dans cette version de l'application.")
    return